{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from srs.database import connect_to_db\n",
    "from srs.utilities import Sentence, tokenize\n",
    "from nltk import pos_tag\n",
    "from collections import Counter\n",
    "import math\n",
    "import word2vec\n",
    "import os\n",
    "import numpy as np\n",
    "# Loading Word2Vec model\n",
    "current_directory = os.path.dirname(os.path.realpath(\"__file__\"))\n",
    "model_path = os.path.join(current_directory[:-6], 'srs/predictor_data/text8.bin')\n",
    "model = word2vec.load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following functions accumulate all the sentences by category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_category_dict():\n",
    "    \"\"\"Build a dictionary whose key is the category tuple, and the value is a list of product_ids:\"\"\"\n",
    "    client, db = connect_to_db()\n",
    "    cursor = db.product_collection.find()\n",
    "    category_dict = {}\n",
    "    i = 0\n",
    "    for product in cursor:\n",
    "        i += 1   \n",
    "        if i % 10000 == 0:\n",
    "            print i\n",
    "        category = product['category']\n",
    "        category_short = tuple(category[:3]) #generally category is 4-tuple. Now limit to the first three tuple\n",
    "        product_id = product['product_id']\n",
    "\n",
    "        if category_short not in category_dict:\n",
    "            category_dict[category_short] = [product_id]\n",
    "        else:\n",
    "            category_dict[category_short].append(product_id)\n",
    "    client.close()\n",
    "    \n",
    "    return category_dict\n",
    "\n",
    "def show_category(category_dict, min_product_num):\n",
    "    \"\"\"Sort the categories according to the number of products in that category, and print them from top\"\"\"\n",
    "    category_list_sorted = []\n",
    "    category_list = []\n",
    "    for key in category_dict:\n",
    "        length = len(category_dict[key])\n",
    "        category_list.append([length, key])\n",
    "    category_list_sorted = sorted(category_list, key=lambda tup: tup[0], reverse=True)\n",
    "\n",
    "    for category_data in category_list_sorted:\n",
    "        if category_data[0] > min_product_num:\n",
    "            print category_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category_dict = get_category_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[201512, (u'Cell Phones & Accessories', u'Cases', u'Basic Cases')]\n",
      "[54232, (u'Electronics', u'Computers & Accessories', u'Laptop & Netbook Computer Accessories')]\n",
      "[50234, (u'Electronics', u'Computers & Accessories', u'Cables & Accessories')]\n",
      "[46040, (u'Electronics', u'Accessories & Supplies', u'Audio & Video Accessories')]\n",
      "[40292, (u'Electronics', u'Camera & Photo', u'Accessories')]\n",
      "[36801, (u'Electronics', u'Computers & Accessories', u'Touch Screen Tablet Accessories')]\n",
      "[26273, (u'Electronics', u'Computers & Accessories', u'Computer Components')]\n",
      "[25569, (u'Electronics', u'Portable Audio & Video', u'MP3 Players & Accessories')]\n",
      "[25256, (u'Cell Phones & Accessories', u'Accessories', u'Accessory Kits')]\n",
      "[16506, (u'Cell Phones & Accessories', u'Accessories', u'Chargers')]\n",
      "[15195, (u'Cell Phones & Accessories', u'Accessories', u'Screen Protectors')]\n",
      "[14752, (u'Electronics', u'Car & Vehicle Electronics', u'Car Electronics')]\n",
      "[11840, (u'Electronics', u'Computers & Accessories', u'Data Storage')]\n",
      "[11747, (u'Electronics', u'Camera & Photo', u'Bags & Cases')]\n",
      "[9669, (u'Cell Phones & Accessories', u'Accessories', u'Headsets')]\n",
      "[9326, (u'Cell Phones & Accessories', u'Accessories', u'Batteries')]\n",
      "[9150, (u'Electronics', u'Computers & Accessories', u'Laptops')]\n",
      "[9050, (u'Electronics', u'Car & Vehicle Electronics', u'Vehicle Electronics Accessories')]\n",
      "[8414, (u'Electronics', u'Camera & Photo', u'Lighting & Studio')]\n",
      "[8174, (u'Electronics', u'Home Audio', u'Stereo Components')]\n",
      "[7916, (u'Electronics', u'Camera & Photo', u'Digital Cameras')]\n",
      "[7585, (u'Electronics', u'Computers & Accessories', u'Networking Products')]\n",
      "[7472, (u'Electronics', u'Accessories & Supplies', u'Batteries, Chargers & Accessories')]\n",
      "[6351, (u'Cell Phones & Accessories', u'Accessories', u'Replacement Parts')]\n",
      "[6024, (u'Cell Phones & Accessories', u'Cell Phones', u'Unlocked Cell Phones')]\n",
      "[5953, (u'Cell Phones & Accessories', u'Accessories', u'Data Cables')]\n",
      "[5689, (u'Cell Phones & Accessories', u'Accessories', u'Car Accessories')]\n",
      "[5123, (u'Electronics', u'GPS & Navigation', u'GPS System Accessories')]\n",
      "[4485, (u'Electronics', u'Computers & Accessories')]\n",
      "[4227, (u'Electronics', u'Television & Video', u'Televisions')]\n",
      "[4081, (u'Cell Phones & Accessories', u'Cases', u'Holsters & Clips')]\n",
      "[4027, (u'Electronics', u'Accessories & Supplies', u'Telephone Accessories')]\n",
      "[3870, (u'Electronics', u'Computers & Accessories', u'Desktops')]\n",
      "[3812, (u'Electronics', u'Camera & Photo', u'Video Surveillance')]\n",
      "[3737, (u'Electronics', u'Camera & Photo', u'Lenses')]\n",
      "[3731, (u'Electronics', u'Computers & Accessories', u'Monitors')]\n",
      "[3694, (u'Electronics', u'Camera & Photo', u'Tripods & Monopods')]\n",
      "[3346, (u'Electronics', u'Camera & Photo', u'Binoculars & Scopes')]\n",
      "[3346, (u'Cell Phones & Accessories', u'Accessories', u'Stylus Pens')]\n",
      "[3346, (u'Electronics', u'eBook Readers & Accessories', u'Covers')]\n",
      "[3149, (u'Electronics', u'Camera & Photo', u'Video')]\n",
      "[3037, (u'Electronics', u'Computers & Accessories', u'PDAs, Handhelds & Accessories')]\n",
      "[2976, (u'Electronics', u'Portable Audio & Video', u'CB & Two-Way Radios')]\n",
      "[2944, (u'Cell Phones & Accessories', u'Accessories', u'Phone Charms')]\n",
      "[2467, (u'Electronics', u'Television & Video', u'DVD Players & Recorders')]\n",
      "[2439, (u'Electronics', u'Computers & Accessories', u'Tablets')]\n",
      "[2340, (u'Electronics', u'Accessories & Supplies', u'Blank Media')]\n",
      "[1832, (u'Electronics', u'Computers & Accessories', u'External Components')]\n",
      "[1665, (u'Electronics', u'Accessories & Supplies')]\n",
      "[1633, (u'Electronics', u'Camera & Photo', u'Film Photography')]\n",
      "[1559, (u'Electronics', u'Computers & Accessories', u'Routers')]\n",
      "[1543, (u'Electronics', u'Camera & Photo')]\n",
      "[1486, (u'Electronics', u'Computers & Accessories', u'Video Projectors')]\n",
      "[1459, (u'Electronics', u'Accessories & Supplies', u'Cord Management')]\n",
      "[1389, (u'Cell Phones & Accessories', u'Cases', u'Armbands')]\n",
      "[1347, (u'Cell Phones & Accessories', u'Accessories')]\n",
      "[1211, (u'Electronics', u'Security & Surveillance', u'Home Security Systems')]\n",
      "[1204, (u'Electronics', u'Camera & Photo', u'Flashes')]\n",
      "[1171, (u'Electronics', u'Portable Audio & Video', u'Radios')]\n",
      "[1134, (u'Electronics', u'Computers & Accessories', u'Webcams')]\n",
      "[1126, (u'Electronics', u'GPS & Navigation', u'Sports & Handheld GPS')]\n",
      "[1088, (u'Electronics', u'eBook Readers & Accessories', u'Skins')]\n",
      "[1005, (u'Electronics', u'Camera & Photo', u'Underwater Photography')]\n"
     ]
    }
   ],
   "source": [
    "# Shows all the main categories (up to 3rd level) and the number of product it contains:\n",
    "min_product_num = 1000\n",
    "show_category(category_dict, min_product_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following three functions collects sentences from one category, obtain each word's tf-idf score, and choose aspect candidates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_sentence_from_category(category):\n",
    "    \"\"\"Obtain all the review sentences from a category tuple:\"\"\"\n",
    "    client, db = connect_to_db()\n",
    "    product_id_list = category_dict[category]\n",
    "    sentence_list = []\n",
    "    review_num = 0\n",
    "    for product_id in product_id_list:\n",
    "        query_res = list(db.product_collection.find({\"product_id\": product_id}))\n",
    "        contents = query_res[0][\"contents\"]\n",
    "        sentence_list += contents\n",
    "        review_num += len(query_res[0][\"review_ids\"])\n",
    "    print \"Number of products {0}\\nNumber of reviews: {1}\\nNumber of sentences: {2}\".format(len(product_id_list), review_num, len(sentence_list))\n",
    "    client.close()\n",
    "    return sentence_list\n",
    "\n",
    "\n",
    "def get_tf_idf(sentence_list):\n",
    "    \"\"\"Get tf-idf score for each word\n",
    "       The dictionary records for each word as a key, the [num_word, num_doc] value, where num_word means the number of \n",
    "       that word in the sentence_list, and num_doc means the number of sentences this word appears in.\n",
    "    \"\"\"\n",
    "    word_statistics = {}\n",
    "    i = 0\n",
    "    print \"Number of sentences processed:\"\n",
    "    # Getting each word's statistics: [num_word, num_doc]\n",
    "    for sentence in sentence_list:\n",
    "        i += 1\n",
    "        if i % 10000 == 0:\n",
    "            print i\n",
    "        tokens = tokenize(sentence, stem = False)\n",
    "        tokens_count = Counter(tokens)\n",
    "        for word in tokens_count:        \n",
    "            if word not in word_statistics:\n",
    "                word_statistics[word] = [tokens_count[word], 1]\n",
    "            else:\n",
    "                word_statistics[word][0] += tokens_count[word]\n",
    "                word_statistics[word][1] += 1\n",
    "      \n",
    "    total_num_doc = len(sentence_list)\n",
    "    word_tf_idf = []\n",
    "    \n",
    "    # Getting the maximum word frequency:\n",
    "    max_word_freq = 0\n",
    "    for word in word_statistics:\n",
    "        if word_statistics[word][0] > max_word_freq:\n",
    "            max_word_freq = word_statistics[word][0]\n",
    "    \n",
    "    # Getting the tf-idf score for each word\n",
    "    for word in word_statistics:\n",
    "        tf = float(word_statistics[word][0]) / max_word_freq\n",
    "        num_doc = word_statistics[word][1]\n",
    "        idf = math.log(float(total_num_doc)/(0 + num_doc)) \n",
    "        word_tf_idf.append([word, tf * idf, tf, idf])\n",
    "            \n",
    "    # Sorting the word_tf_idf list:\n",
    "    word_tf_idf = sorted(word_tf_idf, key=lambda tup: tup[1], reverse=True)\n",
    "    return word_tf_idf\n",
    "\n",
    "\n",
    "def get_aspect_cadidate(word_tf_idf, tag_list = [\"NN\"], score_threshold = 0.8):\n",
    "    '''Get cadidate aspects from word_tf_idf. Only words whose tag belong to tag_list and score > threshold will pass'''\n",
    "    aspect_cadidate = []\n",
    "    for word_data in word_tf_idf:\n",
    "        word = word_data[0]\n",
    "        tf_idf = word_data[1]\n",
    "        word_tag = pos_tag(word)[0]      \n",
    "        # If any of the tag string (e.g. \"NN\") in the given tag_list appears in the word's tag (e.g. \"NNS\")\n",
    "        if any(tag in word_tag for tag in tag_list) and word_data[1] >= score_threshold:\n",
    "            aspect_cadidate_data = [word, tf_idf, word_tag[1]]\n",
    "            aspect_cadidate.append(aspect_cadidate_data)\n",
    "            print [word, '%0.2f' % tf_idf, word_tag[1]]\n",
    "        if word_data[1] < score_threshold:\n",
    "            break\n",
    "            \n",
    "    return aspect_cadidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of products 7916\n",
      "Number of reviews: 203836\n",
      "Number of sentences: 1724928\n"
     ]
    }
   ],
   "source": [
    "# Sample categories, with decreasing number of sentences\n",
    "category = (\"Electronics\", \"Camera & Photo\", \"Digital Cameras\") #Control Group: 7916 products, 203836 reviews, 1724928 sentences\n",
    "# category = (u'Electronics', u'Computers & Accessories', u'Tablets') #2439 products, 99311 reviews, 781032 sentences\n",
    "# category = (u'Cell Phones & Accessories', u'Cell Phones', u'No-Contract Cell Phones') # 743 products, 32200 reviews, 221681 sentences\n",
    "# category = (u'Cell Phones & Accessories', u'Accessories', u'Bluetooth Speakers') #609 products, 38847 reviews, 233048 sentences\n",
    "# category = (u'Electronics', u'Portable Audio & Video', u'Portable DVD Players') #222 products, 3977 reviews, 22476 sentences\n",
    "sentence_list = get_sentence_from_category(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_tf_idf= get_tf_idf(sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'camera', '1.22', 'VB']\n",
      "[u'pictures', '0.65', 'NN']\n",
      "[u'great', '0.63', 'NN']\n",
      "[u'good', '0.56', 'NN']\n",
      "[u'quality', '0.50', 'NN']\n",
      "[u'like', '0.46', 'NN']\n",
      "[u'lens', '0.44', 'NN']\n",
      "[u'get', '0.44', 'NN']\n",
      "[u'take', '0.43', 'VB']\n",
      "[u'canon', '0.41', 'VB']\n",
      "[u'zoom', '0.40', 'NN']\n",
      "[u'cameras', '0.38', 'VB']\n",
      "[u'photos', '0.37', 'NN']\n",
      "[u'battery', '0.37', 'VB']\n",
      "[u'easy', '0.36', 'VB']\n",
      "[u'really', '0.36', 'NN']\n",
      "[u'video', '0.36', 'NN']\n",
      "[u'time', '0.36', 'NN']\n",
      "[u'picture', '0.35', 'NN']\n",
      "[u'even', '0.34', 'NN']\n",
      "[u'digital', '0.33', 'NN']\n",
      "[u'better', '0.33', 'NN']\n",
      "[u'much', '0.32', 'NN']\n",
      "[u'flash', '0.32', 'NN']\n",
      "[u'bought', '0.32', 'NN']\n",
      "[u'price', '0.31', 'NN']\n",
      "[u'light', '0.30', 'NN']\n"
     ]
    }
   ],
   "source": [
    "tag_list = [\"NN\",\"VB\"]  # Include in VB since some nouns are mis-classified as verbs\n",
    "aspect_candidate_list = get_aspect_cadidate(word_tf_idf, tag_list, score_threshold = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following functions start from a seed_word list, find the word list that serves as a dict for each seed_word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_similarity(word1, word2):\n",
    "    \"\"\"Find the similarity between two words, which equals the dot product of their vectors\"\"\"\n",
    "    if word1 in model:\n",
    "        word1_vec = model[word1]\n",
    "    else:\n",
    "        word1_vec = np.zeros([100])\n",
    "        print word1_vec\n",
    "    if word2 in model:\n",
    "        word2_vec = model[word2]\n",
    "    else:\n",
    "        word2_vec = np.zeros([100])\n",
    "    similarity = np.dot(word1_vec, word2_vec)\n",
    "    return similarity\n",
    "\n",
    "def get_word_list_from_aspect_candidates(seed_word, word_tf_idf, similarity_threshold, score_threshold):\n",
    "    \"\"\"Method 1: directly find the word list from all words whose similarity with the seed_word and tf-idf score are above \n",
    "    certain threshold\"\"\"\n",
    "    word_list = []\n",
    "    for word_data in word_tf_idf:\n",
    "        word = word_data[0]\n",
    "        tf_idf = word_data[1]\n",
    "        if tf_idf > score_threshold:\n",
    "            similarity = get_similarity(seed_word, word)\n",
    "            if similarity > similarity_threshold:\n",
    "                word_list.append([word, similarity, tf_idf])              \n",
    "    word_list_sorted = sorted(word_list, key=lambda tup: tup[1], reverse=True)\n",
    "    return word_list_sorted\n",
    "\n",
    "\n",
    "def get_word_list_by_tf_idf(seed_word_list, sentence_list, num_words_in_list):\n",
    "    \"\"\"Method 2: Find the word_list who can distinguish the chosen sentences from other sentences\"\"\"\n",
    "    \n",
    "    # For each seed_word in seed_word_list, get the word_data for all sentences. word_data has 4 fields [num_word_total, num_doc_total, \n",
    "    # num_word_in_topic, num_doc_in_topic], the first two are from all sentences, and the latter two are from the sentences \n",
    "    # that contain the seed_word.   \n",
    "    num_seed_word = len(seed_word_list)\n",
    "    word_statistics_dic_list = [{} for i in range(num_seed_word)]\n",
    "    \n",
    "    num_sentence_topic_list = [0 for k in range(num_seed_word)]\n",
    "    num_sentence_total_list = [0 for k in range(num_seed_word)]\n",
    "    i = 0\n",
    "    print \"Number of sentences processed:\"\n",
    "    for sentence in sentence_list: \n",
    "        i += 1\n",
    "        if i % 10000 == 0:\n",
    "            print i\n",
    "        tokens = tokenize(sentence, stem = False)\n",
    "        tokens_count = Counter(tokens)\n",
    "        for word in tokens_count:\n",
    "            # check for each seed_word:\n",
    "            for k in range(num_seed_word):\n",
    "                seed_word = seed_word_list[k]\n",
    "                if seed_word in sentence: \n",
    "                    num_sentence_topic_list[k] += 1\n",
    "                    num_sentence_total_list[k] += 1\n",
    "                    if word not in word_statistics_dic_list[k]:\n",
    "                        word_statistics_dic_list[k][word] = [tokens_count[word], 1, tokens_count[word], 1]\n",
    "                    else:\n",
    "                        word_statistics_dic_list[k][word][0] += tokens_count[word]\n",
    "                        word_statistics_dic_list[k][word][1] += 1\n",
    "                        word_statistics_dic_list[k][word][2] += tokens_count[word]\n",
    "                        word_statistics_dic_list[k][word][3] += 1\n",
    "                else:\n",
    "                    num_sentence_total_list[k] += 1\n",
    "                    if word not in word_statistics_dic_list[k]:\n",
    "                        word_statistics_dic_list[k][word] = [tokens_count[word], 1, 0, 0]\n",
    "                    else:\n",
    "                        word_statistics_dic_list[k][word][0] += tokens_count[word]\n",
    "                        word_statistics_dic_list[k][word][1] += 1\n",
    "\n",
    "    # Get the maximum word frequency for each seed_word group:\n",
    "    word_tf_idf_ratio_list = [[] for k in range(num_seed_word)]\n",
    "    max_num_word_total_list =[0 for k in range(num_seed_word)]\n",
    "    max_num_word_topic_list =[0 for k in range(num_seed_word)] \n",
    "    for k in range(num_seed_word):    \n",
    "        for word in word_statistics_dic_list[k]:\n",
    "            word_data = word_statistics_dic_list[k][word]\n",
    "            if word_data[0] > max_num_word_total_list[k]:\n",
    "                max_num_word_total_list[k] = word_data[0]\n",
    "            if word_data[2] > max_num_word_topic_list[k]:\n",
    "                max_num_word_topic_list[k] = word_data[2]\n",
    "    \n",
    "    # Get tf_idf adjusted ratio for each word, to measure how this word can distinguish the topic sentences:\n",
    "    for k in range(num_seed_word):        \n",
    "        for word in word_statistics_dic_list[k]:\n",
    "            word_data = word_statistics_dic_list[k][word]\n",
    "            num_word_total = word_data[0]\n",
    "            num_word_topic = word_data[2]\n",
    "            num_doc_total = word_data[1]   \n",
    "            num_doc_topic = word_data[3] \n",
    "        \n",
    "            if num_doc_topic == 0 or num_doc_total == 0:\n",
    "                word_tf_idf_ratio_list[k].append([word, 0])\n",
    "                continue\n",
    "\n",
    "            tf_topic = float(num_word_topic) / max_num_word_topic_list[k]\n",
    "            tf_total = float(num_word_total) / max_num_word_total_list[k]\n",
    "            tf_ratio = (tf_topic/num_word_topic) / (tf_total/num_doc_total)\n",
    "\n",
    "            idf_topic = math.log(float(num_sentence_topic_list[k]) / num_doc_topic)\n",
    "            idf_total = math.log(float(num_sentence_total_list[k]) / num_doc_total) \n",
    "\n",
    "            word_tf_idf_ratio_list[k].append([word, tf_topic * math.log(tf_ratio) * idf_total, tf_topic, tf_total, tf_ratio, idf_topic, idf_total])\n",
    "\n",
    "        word_tf_idf_ratio_list[k].sort(key=lambda tup: tup[1], reverse=True)\n",
    "\n",
    "    word_tf_idf_ratio_list = [item[:num_words_in_list] for item in word_tf_idf_ratio_list]\n",
    "    \n",
    "    return word_tf_idf_ratio_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'pictures', 0.99999997268218732, 0.6495218245632511],\n",
       " [u'photos', 0.86083627362442172, 0.37072616666455493],\n",
       " [u'picture', 0.61262880792408558, 0.35469257714975955],\n",
       " [u'video', 0.53999254308776479, 0.3572299834316976],\n",
       " [u'flash', 0.47092313744007452, 0.3188676566055583],\n",
       " [u'zoom', 0.40573301108039994, 0.40380737966801256],\n",
       " [u'cameras', 0.36868705644628258, 0.3786131470313853],\n",
       " [u'digital', 0.35883936250750026, 0.33130751879204],\n",
       " [u'camera', 0.35455396198588562, 1.223331569583933],\n",
       " [u'like', 0.26126584994220436, 0.46283471998808356]]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the word list from all words whose similarity with the seed_word and tf-idf score are above a certain threshold\n",
    "word_list1 = get_word_list_from_aspect_candidates('pictures', word_tf_idf, similarity_threshold = 0.25, score_threshold = 0.3)\n",
    "word_list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed_word_list = [\"battery\",\"pictures\",\"price\",\"zoom\",\"ease of use\",\"detection\",\"design\",\"video\",\"quality\",\"screen\",\"size\"]\n",
    "word_list2 = get_word_list_by_tf_idf(seed_word_list, sentence_list, num_words_in_list = 15)\n",
    "word_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_list_ours = {\n",
    "    \"battery\": [\"batteri\", \"charger\"], \n",
    "    \"pictures\": [\"pictur\", \"imag\", \"shot\"], \n",
    "    \"price\": [\"cheap\",\"cheaper\", \"expens\", \"afford\", \"price\"], \n",
    "    \"zoom\": [\"zoom\", \"len\"], \n",
    "    \"ease of use\": [\"easi\", \"simpl\", \"easili\", \"simpli\", \"use\"], \n",
    "    \"detection\": [\"detect\", \"auto\", \"mode\", \"smart\", \"focus\"], \n",
    "    \"design\": [\"design\", \"nice\", \"beatiful\", \"color\", \"pretti\"], \n",
    "    \"video\": [\"clear\", \"video\"], \n",
    "    \"quality\": [\"qualiti\"], \n",
    "    \"screen\": [\"screen\", \"display\"], \n",
    "    \"size\": [\"size\", \"big\", \"small\", \"fit\", \"carri\", \"pocket\", \"bulki\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"battery\": ['battery', 'life', 'camera', 'charger', 'charge', 'batteries', 'extra', 'good', 'use', 'long', 'card', 'one', 'pictures', 'rechargeable', 'charged']\n",
      "\"pictures\": ['pictures', 'camera', 'takes', 'take', 'great', 'good', 'taking', 'quality', 'use', 'took', 'easy', 'taken', 'get', 'clear', 'like']\n",
      "\"price\": ['price', 'camera', 'great', 'good', 'quality', 'range', 'priced', 'features', \"it's\", 'cameras', 'one', 'better', 'best', 'amazon', 'worth']\n",
      "\"zoom\": ['zoom', 'x', 'camera', 'optical', 'lens', 'great', 'good', 'video', 'pictures', 'digital', 'quality', 'mm', 'use', 'image', 'zooming']\n",
      "\"ease of use\": ['ease', 'use', 'quality', 'camera', 'picture', 'great', 'features', 'size', 'pictures', 'love', 'good', 'price', \"it's\", 'image', 'like']\n",
      "\"detection\": ['detection', 'face', 'smile', 'mode', 'camera', 'focus', 'features', 'works', 'blink', 'phase', 'auto', '+', 'image', 'like', 'feature']\n",
      "\"design\": ['design', 'designed', 'camera', 'lens', 'quality', 'use', 'like', \"it's\", 'good', 'great', 'flaw', 'easy', 'compact', 'one', 'cameras']\n",
      "\"video\": ['video', 'videos', 'camera', 'quality', 'hd', 'great', 'good', 'pictures', 'zoom', 'mode', 'recording', 'use', 'also', 'take', 'sound']\n",
      "\"quality\": ['quality', 'picture', 'camera', 'image', 'good', 'pictures', 'great', 'video', 'high', 'photos', 'use', 'better', 'excellent', 'zoom', 'price']\n",
      "\"screen\": ['screen', 'lcd', 'camera', 'touch', 'see', 'use', 'view', 'pictures', 'large', 'like', 'bright', 'viewfinder', 'great', 'touchscreen', 'picture']\n",
      "\"size\": ['size', 'camera', 'small', 'quality', 'good', 'sized', 'great', 'pocket', \"it's\", 'weight', 'x', 'compact', 'sensor', 'image', 'pictures']\n"
     ]
    }
   ],
   "source": [
    "# Show word_list for each seed_word\n",
    "num_seed_word = len(word_list2)\n",
    "word_dic = {}\n",
    "for k in range(num_seed_word):\n",
    "    word_dic[seed_word_list[k]] = [str(item[0]) for item in word_list2[k]]\n",
    "for word in word_dic:\n",
    "    print '\"%s\": %s'%(word, word_dic[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
