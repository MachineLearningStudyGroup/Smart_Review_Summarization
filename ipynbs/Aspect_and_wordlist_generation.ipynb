{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient, ASCENDING\n",
    "from srs.database import connect_to_db\n",
    "from srs.utilities import Sentence, tokenize\n",
    "from nltk import pos_tag\n",
    "from collections import Counter\n",
    "import math\n",
    "import word2vec\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import gzip\n",
    "import ast\n",
    "# Loading Word2Vec model\n",
    "current_directory = os.path.dirname(os.path.realpath(\"__file__\"))\n",
    "model_path = os.path.join(current_directory[:-6], 'srs/predictor_data/text8.bin')\n",
    "model = word2vec.load(model_path)\n",
    "def sort_list(list, sort_index, reverse = True):\n",
    "    list_sorted = sorted(list, key=lambda tup: tup[sort_index], reverse = reverse)\n",
    "    return list_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain the prod_dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "    g = gzip.open(path, 'r')\n",
    "    for l in g:\n",
    "        yield ast.literal_eval(l)\n",
    "\n",
    "\n",
    "def construct_prod_dict(meta_file_path_list):\n",
    "    \"\"\"return a dictionary for product metadata\"\"\"\n",
    "    prod_dict = {}\n",
    "    for meta_file_path in meta_file_path_list:\n",
    "        metaParser = parse(meta_file_path)\n",
    "        client, db = connect_to_db()\n",
    "        i = 0       \n",
    "        print \"Building the product dictionary for %s\" % meta_file_path\n",
    "        for meta in metaParser:\n",
    "            i+=1\n",
    "            if i % 100000 == 0:\n",
    "                print i\n",
    "            product_id = meta['asin']\n",
    "            category = meta['categories'][0]\n",
    "            product_name = \"\"\n",
    "            brand = \"\"\n",
    "            if 'title' in meta:\n",
    "                inter = meta['title'].split()\n",
    "                if len (inter) > 1:\n",
    "                    product_name_short = inter[0] + ' ' + inter[1]\n",
    "                else:\n",
    "                    product_name_short = inter[0]\n",
    "            if 'brand' in meta:\n",
    "                brand = meta['brand']\n",
    "            prod_dict[product_id]={'category': category, 'product_name': product_name_short, 'brand': brand}\n",
    "        print i\n",
    "    return prod_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the product dictionary for ../../Datasets/Full_Reviews/meta_Electronics.json.gz\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "498196\n",
      "Building the product dictionary for ../../Datasets/Full_Reviews/meta_Cell_Phones_and_Accessories.json.gz\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "346793\n"
     ]
    }
   ],
   "source": [
    "Electronics_Meta_Path = '../../Datasets/Full_Reviews/meta_Electronics.json.gz'\n",
    "Phone_Meta_Path = '../../Datasets/Full_Reviews/meta_Cell_Phones_and_Accessories.json.gz'\n",
    "\n",
    "prod_dict = construct_prod_dict([Electronics_Meta_Path,Phone_Meta_Path])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following functions accumulate all the sentences by category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_category_dict(prod_dict):\n",
    "    \"\"\"Build a dictionary whose key is the category tuple, and the value is a list of product_ids:\"\"\"\n",
    "    client, db = connect_to_db()\n",
    "    cursor = db.product_collection.find()\n",
    "    category_dict = {}\n",
    "    i = 0\n",
    "    for product in cursor:\n",
    "        i += 1   \n",
    "        if i % 100000 == 0:\n",
    "            print i\n",
    "        category = product['category']\n",
    "        category_short = tuple(category[:4]) #generally category is 4-tuple. Now limit to the first three tuple\n",
    "        product_id = product['product_id']\n",
    "        product_name = \"\"\n",
    "        brand = \"\"\n",
    "        if product_id in prod_dict:\n",
    "            product_info = prod_dict[product_id]\n",
    "            if 'product_name' in product_info:\n",
    "                product_name = product_info['product_name']\n",
    "            if 'brand' in product_info:\n",
    "                brand = product_info['brand']\n",
    "\n",
    "        if category_short not in category_dict:\n",
    "            category_dict[category_short] = {\"product_id\": [product_id], \"brand_list\": [], \"product_name_list\": []}\n",
    "        else:\n",
    "            category_dict[category_short]['product_id'].append(product_id)\n",
    "            \n",
    "        if len(product_name) > 0:\n",
    "            category_dict[category_short]['product_name_list'].append(product_name)\n",
    "        if len(brand) > 0:\n",
    "            if brand not in category_dict[category_short]['brand_list']:\n",
    "                category_dict[category_short]['brand_list'].append(brand)\n",
    "            \n",
    "    client.close()\n",
    "    print i\n",
    "  \n",
    "    return category_dict\n",
    "\n",
    "\n",
    "def sort_category_dict(category_dict, isPrint = False):\n",
    "    \"\"\"Sort the categories according to the number of products in that category, and print them from top\"\"\"\n",
    "    category_list_sorted = []\n",
    "    category_list = []\n",
    "\n",
    "    for key in category_dict:\n",
    "        length = len(category_dict[key]['product_id'])\n",
    "        category_list.append([key,length,key[:3],0])\n",
    "    category_list_sorted = sorted(category_list, key=lambda tup: (tup[2],tup[1]), reverse=True)\n",
    "    \n",
    "    category_list_sorted_dict = {}\n",
    "    for Id in range(len(category_list_sorted)):\n",
    "        category_list_sorted[Id][3]=Id\n",
    "        category = category_list_sorted[Id][0]\n",
    "        category_dict[category][\"category_id\"] = Id\n",
    "        category_list_sorted_dict[Id] = category_list_sorted[Id][:3]\n",
    "    \n",
    "    if isPrint:\n",
    "        for Id in range(len(category_list_sorted)):\n",
    "            print Id, category_list_sorted_dict[Id][:2]\n",
    "        \n",
    "    return category_list_sorted_dict\n",
    "\n",
    "\n",
    "def combine_category_custom(category_dict_raw, category_list_sorted_dict):\n",
    "    category_dict = copy.deepcopy(category_dict_raw)\n",
    "    print \"Number of categories in original set: %g\"%len(category_dict_raw)\n",
    "    print \"Combined category ID:\"\n",
    "    f = open('Aspect_and_wordlist_txt/combined_dict.txt','r')\n",
    "    for line in f:\n",
    "        combine_info = eval(line)\n",
    "        print combine_info\n",
    "        if len(combine_info) > 0:\n",
    "            Id_to_combine = combine_info[0]\n",
    "            name_info = combine_info[1]\n",
    "            category_name_combined = category_list_sorted_dict[name_info[0]][0][:name_info[1]]\n",
    "            category_id = category_dict_raw[category_list_sorted_dict[name_info[0]][0]][\"category_id\"]\n",
    "            new_prod_id_list = []\n",
    "            new_product_name_list = []\n",
    "            new_brand_list = []\n",
    "            for Id in Id_to_combine:\n",
    "                category_name = category_list_sorted_dict[Id][0]\n",
    "                new_prod_id_list += category_dict[category_name][\"product_id\"]\n",
    "                new_product_name_list += category_dict[category_name][\"product_name_list\"]\n",
    "                new_brand_list += category_dict[category_name][\"brand_list\"]\n",
    "                category_dict.pop(category_name, 0)\n",
    "            category_dict[category_name_combined] = {\"category_id\": category_id,\"product_id\": new_prod_id_list,\\\n",
    "                        \"product_name_list\": new_product_name_list, \"brand_list\": new_brand_list}\n",
    "    f.close()\n",
    "    print \"Number of categories in the new dict: %g\"%len(category_dict)\n",
    "      \n",
    "    return category_dict\n",
    "\n",
    "\n",
    "def combine_small_category(category_dict_raw, category_list_sorted, prod_num_threshold = 100, shrink_level = 3):\n",
    "    category_dict = copy.deepcopy(category_dict_raw)\n",
    "    i = 0\n",
    "    for i in range(len(category_list_sorted)):\n",
    "        i += 1\n",
    "        category_name = category_list_sorted[-i][1]\n",
    "        prod_num = category_list_sorted[-i][0]\n",
    "        if prod_num > prod_num_threshold:\n",
    "            break\n",
    "        if len(category_name) > shrink_level:\n",
    "            category_name_shrink = category_name[:shrink_level]\n",
    "            if category_name_shrink in category_dict:\n",
    "                category_dict[category_name_shrink] += category_dict[category_name]\n",
    "                category_dict.pop(category_name,0)\n",
    "                print \"{0} combined into {1}\".format(category_name_shrink, category_name)\n",
    "            else:\n",
    "                print \"{0} not combined\".format(category_name_shrink)\n",
    "        else:\n",
    "            print \"{0} length not enough.\".format(category_name)\n",
    "    \n",
    "    return category_dict\n",
    "\n",
    "\n",
    "def save_category_dict_to_db(category_dict, dropPrevious = False):\n",
    "    client, db = connect_to_db()\n",
    "    db_category_data = db.category_data\n",
    "    if dropPrevious == True:\n",
    "        db_category_data.delete_many({})\n",
    "    for category in category_dict:\n",
    "        query = {\"category_id\": category_dict[category][\"category_id\"]}\n",
    "        update_field = {\"category\": list(category),\\\n",
    "                        \"prod_id_list\": category_dict[category][\"product_id\"], \\\n",
    "                        \"brand_list\":  category_dict[category][\"brand_list\"],\\\n",
    "                        \"product_name_list\": category_dict[category][\"product_name_list\"]}\n",
    "        db_category_data.update_one(query, {\"$set\": update_field}, True)\n",
    "        \n",
    "    client.close()\n",
    "\n",
    "\n",
    "def show_category_dict_info(category_dict, min_prod_num = 1000):\n",
    "    new_list = []\n",
    "    for category in category_dict:\n",
    "        new_list.append([len(category_dict[category][\"product_id\"]),category,category_dict[category][\"category_id\"]])\n",
    "    \n",
    "    new_list = sorted(new_list, key=lambda tup: tup[0], reverse=True)\n",
    "    \n",
    "    for item in new_list:\n",
    "        if int(item[0]) < min_prod_num:        \n",
    "            break\n",
    "        print \"{0},{1},{2}\".format(item[0],item[1],item[2])\n",
    "\n",
    "\n",
    "def get_sentence_from_category(category_list):\n",
    "    \"\"\"Obtain all the review sentences from a list of category tuple:\"\"\"\n",
    "    if isinstance(category_list, dict):\n",
    "        category_lists = [category_list]\n",
    "    else:\n",
    "        category_lists = category_list\n",
    "    \n",
    "    category_content_list = []\n",
    "    \n",
    "    for category in category_lists:\n",
    "        print \"{0}:\".format(category)\n",
    "        client, db = connect_to_db()\n",
    "        product_id_list = category_dict[category][\"product_id\"]\n",
    "        category_contents = {\"category\": category,\"sentence_list\": [], \"brand_list\": category_dict[category][\"brand_list\"],\\\n",
    "                            \"product_name_list\": category_dict[category][\"product_name_list\"]}\n",
    "        review_num = 0\n",
    "        for product_id in product_id_list:\n",
    "            query_res = list(db.product_collection.find({\"product_id\": product_id}))\n",
    "            contents = query_res[0][\"contents\"]\n",
    "            category_contents['sentence_list'] += contents\n",
    "            review_num += len(query_res[0][\"review_ids\"])\n",
    "        print \"  ({0}, {1}, {2})\".format(len(product_id_list), review_num, len(category_contents['sentence_list']))      \n",
    "        category_content_list.append(category_contents)\n",
    "        \n",
    "    client.close()\n",
    "\n",
    "    return category_content_list\n",
    "\n",
    "\n",
    "def get_sentence_from_category_ensemble(category_dict, max_prod_chosen = 500, min_product_level = 500):\n",
    "    client, db = connect_to_db()\n",
    "    full_sentence_list = []\n",
    "    print \"Getting product categories: (num_sentence_chosen, category):\"\n",
    "    for category in category_dict:\n",
    "        if len(category_dict[category]) < min_product_level:\n",
    "            continue\n",
    "        product_id_list = category_dict[category][\"product_id\"]\n",
    "        random.shuffle(product_id_list)\n",
    "        new_sentence = []\n",
    "        for product_id in product_id_list[:max_prod_chosen]:\n",
    "            query_res = list(db.product_collection.find({\"product_id\": product_id}))\n",
    "            contents = query_res[0][\"contents\"]\n",
    "            new_sentence += contents\n",
    "        print len(new_sentence),category\n",
    "        full_sentence_list += new_sentence\n",
    "    client.close()\n",
    "    print \"Number of sentences: {0}\".format(len(full_sentence_list))\n",
    "    \n",
    "    all_category_content = {\"sentence_list\": full_sentence_list}\n",
    "    return all_category_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "793315\n"
     ]
    }
   ],
   "source": [
    "category_dict_raw = get_category_dict(prod_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categories in original set: 512\n",
      "Combined category ID:\n",
      "[[16, 17], [17, 2]]\n",
      "[[20, 21, 22, 23, 26, 28, 29, 30, 31, 32], [22, 3]]\n",
      "[[38, 39, 40, 41, 42], [38, 3]]\n",
      "[[105, 106], [105, 3]]\n",
      "[[108, 109, 110, 111, 112], [112, 3]]\n",
      "[[139, 140, 141], [139, 3]]\n",
      "[[176, 177, 178, 179, 180, 181, 182, 183, 184], [176, 3]]\n",
      "[[277, 278, 279, 280], [277, 3]]\n",
      "[[282, 283, 284, 285, 286, 287, 288], [282, 3]]\n",
      "[[297, 298, 299, 300, 301], [297, 3]]\n",
      "[[302, 303, 304], [302, 3]]\n",
      "[[308, 309, 310, 311, 312, 313, 314], [308, 3]]\n",
      "[[316, 321], [316, 3]]\n",
      "[[322, 323, 324, 325, 326, 327, 328, 329, 330, 331], [322, 3]]\n",
      "[[356, 357, 358, 359, 360], [356, 3]]\n",
      "[[362, 363, 364, 365, 366], [366, 3]]\n",
      "[[367, 368, 369, 370], [367, 3]]\n",
      "[[371, 372, 373, 374, 375, 376, 377], [371, 3]]\n",
      "[[379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393], [379, 3]]\n",
      "[[399, 400], [399, 3]]\n",
      "[[417, 418, 419, 420, 421], [417, 3]]\n",
      "[[427, 428, 429, 430], [427, 2]]\n",
      "[[433, 434, 435, 436, 437, 438], [433, 2]]\n",
      "[[439, 440, 441, 442, 443, 444, 445], [439, 3]]\n",
      "[[462, 463, 464], [462, 3]]\n",
      "[[469, 470, 471], [469, 3]]\n",
      "Number of categories in the new dict: 396\n"
     ]
    }
   ],
   "source": [
    "category_list_sorted_dict = sort_category_dict(category_dict_raw, isPrint = False)\n",
    "category_dict = combine_category_custom(category_dict_raw, category_list_sorted_dict)\n",
    "save_category_dict_to_db(category_dict, dropPrevious = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207742,(u'Cell Phones & Accessories', u'Cases', u'Waterproof Cases'),439\n",
      "25256,(u'Cell Phones & Accessories', u'Accessories', u'Accessory Kits'),474\n",
      "25245,(u'Electronics', u'Computers & Accessories', u'Touch Screen Tablet Accessories', u'Cases & Sleeves'),129\n",
      "21726,(u'Electronics', u'Portable Audio & Video', u'MP3 Players & Accessories', u'MP3 Player Accessories'),78\n",
      "16275,(u'Electronics', u'Computers & Accessories', u'Laptop & Netbook Computer Accessories', u'Batteries'),155\n",
      "15453,(u'Electronics', u'Camera & Photo', u'Accessories', u'Batteries & Chargers'),332\n",
      "15195,(u'Cell Phones & Accessories', u'Accessories', u'Screen Protectors'),450\n",
      "15051,(u'Electronics', u'Computers & Accessories', u'Laptop & Netbook Computer Accessories', u'Chargers & Adapters'),156\n",
      "13548,(u'Electronics', u'Computers & Accessories', u'Laptop & Netbook Computer Accessories', u'Bags & Cases'),157\n",
      "13115,(u'Electronics', u'Accessories & Supplies', u'Audio & Video Accessories', u'Cables & Interconnects'),401\n",
      "11747,(u'Electronics', u'Camera & Photo', u'Bags & Cases'),322\n",
      "11524,(u'Electronics', u'Computers & Accessories', u'Cables & Accessories', u'Cables & Interconnects'),203\n",
      "10638,(u'Electronics', u'Accessories & Supplies', u'Audio & Video Accessories', u'Headphones'),402\n",
      "9544,(u'Electronics', u'Car & Vehicle Electronics', u'Car Electronics', u'Car Audio'),253\n",
      "9150,(u'Electronics', u'Computers & Accessories', u'Laptops'),154\n",
      "8855,(u'Cell Phones & Accessories', u'Accessories', u'Batteries'),469\n",
      "7915,(u'Electronics', u'Camera & Photo', u'Digital Cameras'),308\n",
      "7416,(u'Cell Phones & Accessories', u'Cell Phones'),433\n",
      "7408,(u'Cell Phones & Accessories', u'Accessories', u'Chargers', u'Car Chargers'),459\n",
      "6912,(u'Electronics', u'Computers & Accessories', u'Data Storage'),176\n",
      "6645,(u'Electronics', u'Computers & Accessories', u'Computer Components', u'Memory'),185\n",
      "6620,(u'Electronics', u'Camera & Photo', u'Accessories', u'Digital Camera Accessories'),333\n",
      "6595,(u'Cell Phones & Accessories', u'Accessories', u'Chargers', u'Travel Chargers'),460\n",
      "6351,(u'Cell Phones & Accessories', u'Accessories', u'Replacement Parts'),452\n",
      "5953,(u'Cell Phones & Accessories', u'Accessories', u'Data Cables'),457\n",
      "5771,(u'Electronics', u'Accessories & Supplies', u'Batteries, Chargers & Accessories', u'AC Adapters'),394\n",
      "5090,(u'Electronics', u'Television & Video', u'Televisions'),22\n",
      "5057,(u'Electronics', u'Computers & Accessories', u'Cables & Accessories', u'Memory Cards'),204\n",
      "4981,(u'Electronics', u'Camera & Photo', u'Accessories', u'Lens Accessories'),334\n",
      "4947,(u'Electronics', u'Home Audio', u'Stereo Components', u'Speakers'),90\n",
      "4928,(u'Electronics', u'Computers & Accessories', u'Data Storage', u'USB Flash Drives'),175\n",
      "4804,(u'Cell Phones & Accessories', u'Accessories', u'Headsets', u'Wired Headsets'),454\n",
      "4781,(u'Electronics', u'Computers & Accessories', u'Cables & Accessories', u'Keyboards'),205\n",
      "4770,(u'Cell Phones & Accessories', u'Accessories', u'Headsets', u'Bluetooth Headsets'),455\n",
      "4576,(u'Cell Phones & Accessories', u'Accessories', u'Car Accessories', u'Car Cradles & Mounts'),465\n",
      "4485,(u'Electronics', u'Computers & Accessories'),228\n",
      "4362,(u'Electronics', u'Camera & Photo', u'Lighting & Studio', u'Photo Studio'),292\n",
      "4348,(u'Electronics', u'Computers & Accessories', u'Cables & Accessories', u'Video Projector Accessories'),206\n",
      "4124,(u'Electronics', u'Car & Vehicle Electronics', u'Vehicle Electronics Accessories', u'Audio & Video Accessories'),230\n",
      "4004,(u'Electronics', u'Camera & Photo', u'Accessories', u'Filters & Accessories'),335\n",
      "3980,(u'Electronics', u'Computers & Accessories', u'Touch Screen Tablet Accessories', u'Screen Protectors'),130\n",
      "3878,(u'Electronics', u'Computers & Accessories', u'Cables & Accessories', u'Mice'),207\n",
      "3870,(u'Electronics', u'Computers & Accessories', u'Desktops'),174\n",
      "3829,(u'Electronics', u'Accessories & Supplies', u'Audio & Video Accessories', u'TV Accessories & Parts'),403\n",
      "3821,(u'Electronics', u'Camera & Photo', u'Lighting & Studio', u'Lighting'),293\n",
      "3783,(u'Electronics', u'Portable Audio & Video', u'MP3 Players & Accessories', u'MP3 Players'),79\n",
      "3737,(u'Electronics', u'Camera & Photo', u'Lenses'),297\n",
      "3731,(u'Electronics', u'Computers & Accessories', u'Monitors'),153\n",
      "3729,(u'Electronics', u'Accessories & Supplies', u'Audio & Video Accessories', u'Connectors & Adapters'),404\n",
      "3694,(u'Electronics', u'Camera & Photo', u'Tripods & Monopods'),282\n",
      "3686,(u'Electronics', u'Computers & Accessories', u'Laptop & Netbook Computer Accessories', u'Replacement Screens'),158\n",
      "3517,(u'Electronics', u'Computers & Accessories', u'Computer Components', u'Fans & Cooling'),186\n",
      "3512,(u'Electronics', u'Computers & Accessories', u'Computer Components', u'Graphics Cards'),187\n",
      "3346,(u'Electronics', u'eBook Readers & Accessories', u'Covers'),15\n",
      "3346,(u'Cell Phones & Accessories', u'Accessories', u'Stylus Pens'),447\n",
      "3215,(u'Electronics', u'Camera & Photo', u'Video Surveillance', u'Surveillance Cameras'),266\n",
      "3176,(u'Electronics', u'Computers & Accessories', u'Cables & Accessories', u'Computer Cable Adapters'),208\n",
      "3155,(u'Electronics', u'Computers & Accessories', u'Laptop & Netbook Computer Accessories', u'Skins & Decals'),159\n",
      "3078,(u'Electronics', u'Accessories & Supplies', u'Audio & Video Accessories', u'Remote Controls'),405\n",
      "3037,(u'Electronics', u'Computers & Accessories', u'PDAs, Handhelds & Accessories'),139\n",
      "3020,(u'Electronics', u'Television & Video', u'DVD Players & Recorders'),38\n",
      "2970,(u'Electronics', u'Computers & Accessories', u'Networking Products', u'Network Adapters'),142\n",
      "2944,(u'Cell Phones & Accessories', u'Accessories', u'Phone Charms'),453\n",
      "2833,(u'Electronics', u'Accessories & Supplies', u'Telephone Accessories', u'Batteries'),353\n",
      "2804,(u'Electronics', u'Car & Vehicle Electronics', u'Vehicle Electronics Accessories'),231\n",
      "2625,(u'Electronics', u'Computers & Accessories', u'Computer Components', u'Motherboards'),188\n",
      "2452,(u'Electronics', u'Car & Vehicle Electronics', u'Car Electronics', u'Car Safety & Security'),254\n",
      "2439,(u'Electronics', u'Computers & Accessories', u'Tablets'),136\n",
      "2379,(u'Electronics', u'Camera & Photo', u'Video', u'Camcorders'),271\n",
      "2353,(u'Electronics', u'Car & Vehicle Electronics', u'Car Electronics', u'Car Video'),255\n",
      "2343,(u'Electronics', u'Accessories & Supplies', u'Audio & Video Accessories', u'Headphone Accessories'),406\n",
      "2340,(u'Electronics', u'Accessories & Supplies', u'Blank Media'),379\n",
      "2298,(u'Electronics', u'Computers & Accessories', u'Touch Screen Tablet Accessories', u'Bundles'),131\n",
      "2281,(u'Electronics', u'GPS & Navigation', u'GPS System Accessories', u'Vehicle Mounts'),114\n",
      "2190,(u'Electronics', u'Computers & Accessories', u'Cables & Accessories', u'Hard Drive Enclosures'),209\n",
      "2187,(u'Electronics', u'Accessories & Supplies', u'Audio & Video Accessories', u'Media Storage & Organization'),407\n",
      "2096,(u'Electronics', u'Camera & Photo', u'Binoculars & Scopes'),316\n",
      "1955,(u'Electronics', u'Home Audio', u'Stereo Components', u'Receivers & Amplifiers'),91\n",
      "1929,(u'Electronics', u'Camera & Photo', u'Accessories', u'Flash Accessories'),336\n",
      "1854,(u'Electronics', u'Computers & Accessories', u'Cables & Accessories', u'Computer Speakers'),210\n",
      "1840,(u'Electronics', u'Computers & Accessories', u'Cables & Accessories', u'Keyboard & Mice Accessories'),211\n",
      "1824,(u'Electronics', u'Portable Audio & Video', u'CB & Two-Way Radios', u'Accessories'),83\n",
      "1813,(u'Electronics', u'Accessories & Supplies', u'Audio & Video Accessories', u'Distribution'),408\n",
      "1804,(u'Cell Phones & Accessories', u'Accessories', u'Chargers', u'Cell Phone Docks'),461\n",
      "1710,(u'Electronics', u'Computers & Accessories', u'Computer Components', u'Power Supplies'),189\n",
      "1701,(u'Electronics', u'Computers & Accessories', u'Cables & Accessories', u'Headsets & Microphones'),212\n",
      "1698,(u'Electronics', u'Computers & Accessories', u'Computer Components', u'Computer Cases'),190\n",
      "1665,(u'Electronics', u'Accessories & Supplies'),423\n",
      "1579,(u'Electronics', u'Car & Vehicle Electronics', u'Vehicle Electronics Accessories', u'Vehicle Audio & Video Installation'),232\n",
      "1559,(u'Electronics', u'Computers & Accessories', u'Routers'),138\n",
      "1543,(u'Electronics', u'Camera & Photo'),352\n",
      "1513,(u'Electronics', u'Computers & Accessories', u'Cables & Accessories', u'Memory Card Readers'),213\n",
      "1486,(u'Electronics', u'Computers & Accessories', u'Video Projectors'),128\n",
      "1460,(u'Electronics', u'Computers & Accessories', u'Touch Screen Tablet Accessories', u'Chargers & Adapters'),132\n",
      "1459,(u'Electronics', u'Accessories & Supplies', u'Cord Management'),371\n",
      "1436,(u'Electronics', u'Computers & Accessories', u'Touch Screen Tablet Accessories', u'Skins & Decals'),133\n",
      "1409,(u'Electronics', u'Computers & Accessories', u'Cables & Accessories', u'Input Devices'),214\n",
      "1374,(u'Electronics', u'Computers & Accessories', u'Computer Components'),191\n",
      "1370,(u'Electronics', u'Computers & Accessories', u'Touch Screen Tablet Accessories'),134\n",
      "1361,(u'Electronics', u'Camera & Photo', u'Accessories', u'Professional Video Accessories'),337\n",
      "1347,(u'Cell Phones & Accessories', u'Accessories'),475\n",
      "1302,(u'Electronics', u'Computers & Accessories', u'Cables & Accessories', u'Monitor Accessories'),215\n",
      "1263,(u'Electronics', u'Computers & Accessories', u'Cables & Accessories', u'Uninterrupted Power Supply (UPS)'),216\n",
      "1238,(u'Electronics', u'Computers & Accessories', u'Networking Products', u'Hubs'),143\n",
      "1211,(u'Electronics', u'Security & Surveillance', u'Home Security Systems'),58\n",
      "1204,(u'Electronics', u'Camera & Photo', u'Flashes'),302\n",
      "1162,(u'Electronics', u'Computers & Accessories', u'Cables & Accessories', u'Keyboard & Mouse Combos'),217\n",
      "1151,(u'Electronics', u'Computers & Accessories', u'Computer Components', u'I/O Port Cards'),192\n",
      "1134,(u'Electronics', u'Computers & Accessories', u'Webcams'),124\n",
      "1126,(u'Electronics', u'GPS & Navigation', u'Sports & Handheld GPS'),112\n",
      "1124,(u'Electronics', u'Computers & Accessories', u'Computer Components', u'Internal Optical Drives'),193\n",
      "1105,(u'Electronics', u'Camera & Photo', u'Film Photography', u'Film Cameras'),305\n",
      "1088,(u'Electronics', u'eBook Readers & Accessories', u'Skins'),10\n",
      "1081,(u'Electronics', u'Computers & Accessories', u'Cables & Accessories', u'Surge Protectors'),218\n",
      "1066,(u'Electronics', u'Computers & Accessories', u'Computer Components', u'CPU Processors'),194\n",
      "1034,(u'Electronics', u'Accessories & Supplies', u'Audio & Video Accessories', u'Antennas'),409\n",
      "1030,(u'Electronics', u'Computers & Accessories', u'Networking Products', u'Switches'),144\n",
      "1022,(u'Electronics', u'Camera & Photo', u'Accessories', u'Tripod & Monopod Accessories'),338\n",
      "1012,(u'Electronics', u'Computers & Accessories', u'Touch Screen Tablet Accessories', u'Stands'),135\n",
      "1004,(u'Electronics', u'Camera & Photo', u'Underwater Photography'),277\n"
     ]
    }
   ],
   "source": [
    "show_category_dict_info(category_dict, min_prod_num = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all_category_content = get_sentence_from_category_ensemble(category_dict, max_prod_chosen = 1000, min_product_level = 0)\n",
    "# get_tf_idf(all_category_content, is_idf_db = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aspect extraction: the following functions collects sentences from one category, obtain each word's tf-idf score, and choose aspect candidates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_tf_idf(sentence_list, is_idf_db = True):\n",
    "    \"\"\"Get tf-idf score for each word\n",
    "       The dictionary records for each word as a key, the [num_word, num_doc] value, where num_word means the number of \n",
    "       that word in the sentence_list, and num_doc means the number of sentences this word appears in.\n",
    "    \"\"\"\n",
    "    word_statistics = {}\n",
    "    db_word_score_list = db.word_score_list\n",
    "    i = 0\n",
    "    print \"Number of sentences processed:\"\n",
    "    # Getting each word's statistics: [num_word, num_doc]\n",
    "    for sentence in sentence_list:\n",
    "        i += 1\n",
    "        if i % 50000 == 0:\n",
    "            print i\n",
    "        tokens = tokenize(sentence, stem = False)\n",
    "        tokens_count = Counter(tokens)\n",
    "        for word in tokens_count:        \n",
    "            if word not in word_statistics:\n",
    "                word_statistics[word] = [tokens_count[word], 1]\n",
    "            else:\n",
    "                word_statistics[word][0] += tokens_count[word]\n",
    "                word_statistics[word][1] += 1\n",
    "      \n",
    "    total_num_doc = len(sentence_list)\n",
    "    word_tf_idf = []\n",
    "    \n",
    "    # Getting the maximum word frequency:\n",
    "    max_word_freq = 0\n",
    "    for word in word_statistics:\n",
    "        if word_statistics[word][0] > max_word_freq:\n",
    "            max_word_freq = word_statistics[word][0]\n",
    "    \n",
    "    # Getting the tf-idf score for each word\n",
    "    print \"Calculating tf-idf:\"\n",
    "    i = 0\n",
    "    for word in word_statistics:\n",
    "        i += 1\n",
    "        if i % 10000 == 0:\n",
    "            print i\n",
    "        tf = float(word_statistics[word][0]) / max_word_freq \n",
    "        # Calculating idf:     \n",
    "        num_doc = word_statistics[word][1]\n",
    "        idf_category = math.log(float(total_num_doc)/(0 + num_doc))\n",
    "        if is_idf_db == True:\n",
    "            word_score = get_word_score_from_db(word, db_word_score_list)\n",
    "            idf_db = word_score[2]\n",
    "        else:\n",
    "            idf_db = 1\n",
    "        word_tf_idf.append([word, tf * idf_db, tf, idf_category, idf_db])\n",
    "            \n",
    "    # Sorting the word_tf_idf list:\n",
    "    word_tf_idf = sorted(word_tf_idf, key=lambda tup: tup[1], reverse=True)\n",
    "    return word_tf_idf, word_statistics\n",
    "\n",
    "\n",
    "def save_word_score_to_db(word_tf_idf):\n",
    "    client, db = connect_to_db()\n",
    "    db.word_score_list.delete_many({})\n",
    "    db.word_score_list.create_index([(\"word\", ASCENDING)])\n",
    "    i = 0\n",
    "    for word_data in word_tf_idf:\n",
    "        i += 1\n",
    "        if i % 10000 == 0:\n",
    "            print i\n",
    "        word = word_data[0]\n",
    "        word_score = word_data[1:]\n",
    "        query = {\"word\": word}\n",
    "        update_field = {\"word_score\": word_score}\n",
    "        \n",
    "        db.word_score_list.update_one(query, {\"$set\": update_field}, True)\n",
    "    client.close()\n",
    "    print \"Total number of words: %g\"%len(word_tf_idf)\n",
    "\n",
    "    \n",
    "def get_word_score_from_db(word, db_word_score_list):\n",
    "    query = db_word_score_list.find({\"word\": word})\n",
    "    if len(query[0]) > 0:\n",
    "        return query[0][\"word_score\"]\n",
    "    else:\n",
    "        return [0,0,0]\n",
    "\n",
    "\n",
    "def get_aspect_cadidate(word_tf_idf, tag_list = [\"NN\"], score_threshold = 0.8):\n",
    "    '''Get cadidate aspects from word_tf_idf. Only words whose tag belong to tag_list and score > threshold will pass'''\n",
    "    aspect_cadidate = []\n",
    "    j = 0\n",
    "    for word_data in word_tf_idf:\n",
    "        word = word_data[0]\n",
    "        tf_idf = word_data[1]\n",
    "        word_tag = pos_tag([word])[0][1]\n",
    "        # If any of the tag string (e.g. \"NN\") in the given tag_list appears in the word's tag (e.g. \"NNS\")\n",
    "        if any(tag in word_tag for tag in tag_list) and (word_data[1] >= score_threshold \\\n",
    "                                                         or (word_data[1] < score_threshold and j <= 20)):\n",
    "            j +=1\n",
    "            aspect_cadidate_data = [word, tf_idf, word_tag]\n",
    "            aspect_cadidate.append(aspect_cadidate_data)\n",
    "            print [word, '%0.2f' % tf_idf, word_tag]\n",
    "        if word_data[1] < score_threshold:\n",
    "            break\n",
    "            \n",
    "    return aspect_cadidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of products 743\n",
      "Number of reviews: 32200\n",
      "Number of sentences: 221681\n"
     ]
    }
   ],
   "source": [
    "# Sample categories, with decreasing number of sentences\n",
    "# category = (\"Electronics\", \"Camera & Photo\", \"Digital Cameras\") #Control Group: 7916 products, 203836 reviews, 1724928 sentences\n",
    "# category = (u'Electronics', u'Computers & Accessories', u'Tablets') #2439 products, 99311 reviews, 781032 sentences\n",
    "category = (u'Cell Phones & Accessories', u'Cell Phones', u'No-Contract Cell Phones') # 743 products, 32200 reviews, 221681 sentences\n",
    "# category = (u'Cell Phones & Accessories', u'Accessories', u'Bluetooth Speakers') #609 products, 38847 reviews, 233048 sentences\n",
    "# category = (u'Electronics', u'Portable Audio & Video', u'Portable DVD Players') #222 products, 3977 reviews, 22476 sentences\n",
    "sentence_list = get_sentence_from_category(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences processed:\n",
      "50000\n",
      "100000\n",
      "150000\n",
      "200000\n",
      "Calculating tf-idf:\n",
      "10000\n",
      "20000\n",
      "30000\n"
     ]
    }
   ],
   "source": [
    "word_tf_idf, _ = get_tf_idf(sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'phone', '3.07', 'NN']\n",
      "[u'minutes', '0.53', 'NNS']\n",
      "[u'tracfone', '0.52', 'NN']\n",
      "[u'use', '0.46', 'NN']\n",
      "[u'phones', '0.45', 'NNS']\n",
      "[u'service', '0.44', 'NN']\n",
      "[u'battery', '0.40', 'NN']\n",
      "[u'screen', '0.39', 'NN']\n",
      "[u\"it's\", '0.36', 'NN']\n",
      "[u'text', '0.35', 'NN']\n",
      "[u'apps', '0.35', 'NN']\n",
      "[u'card', '0.33', 'NN']\n",
      "[u'call', '0.32', 'NN']\n",
      "[u'time', '0.31', 'NN']\n",
      "[u\"don't\", '0.30', 'NN']\n",
      "[u'calls', '0.30', 'NNS']\n",
      "[u'lg', '0.28', 'NN']\n",
      "[u'android', '0.28', 'NN']\n",
      "[u'virgin', '0.28', 'NN']\n",
      "[u'mobile', '0.26', 'NN']\n",
      "[u'g', '0.26', 'NN']\n",
      "[u\"i'm\", '0.24', 'NN']\n",
      "[u'plan', '0.24', 'NN']\n",
      "[u'cell', '0.24', 'NN']\n",
      "[u'price', '0.23', 'NN']\n",
      "[u'bought', '0.23', 'NN']\n",
      "[u'love', '0.22', 'NN']\n",
      "[u'life', '0.22', 'NN']\n",
      "[u'month', '0.22', 'NN']\n",
      "[u\"i've\", '0.22', 'NN']\n",
      "[u'want', '0.22', 'NN']\n",
      "[u'works', '0.22', 'NNS']\n",
      "[u'need', '0.22', 'NN']\n",
      "[u'keyboard', '0.21', 'NN']\n",
      "[u'work', '0.21', 'NN']\n",
      "[u'data', '0.21', 'NNS']\n",
      "[u'number', '0.21', 'NN']\n",
      "[u'camera', '0.21', 'NN']\n"
     ]
    }
   ],
   "source": [
    "tag_list = [\"NN\"]  # Include in VB since some nouns are mis-classified as verbs\n",
    "aspect_candidate_list = get_aspect_cadidate(word_tf_idf, tag_list, score_threshold = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"phone\", \"minutes\", \"tracfone\", \"use\", \"phones\", \"service\", \"battery\", \"screen\", \"it's\", \"text\", \"apps\", \"card\", \"call\", \"time\", \"don't\", \"calls\", \"lg\", \"android\", \"virgin\", \"mobile\", \"g\", \"i'm\", \"plan\", \"cell\", \"price\", \"bought\", \"love\", \"life\", \"month\", \"i've\", \"want\", \"works\", \"need\", \"keyboard\", \"work\", \"data\", \"number\", \"camera\",\n"
     ]
    }
   ],
   "source": [
    "for item in aspect_candidate_list:\n",
    "    print '\"%s\",'%item[0],"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following functions start from a seed_word list, find the word list that serves as a dict for each seed_word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_similarity(word1, word2):\n",
    "    \"\"\"Find the similarity between two words, which equals the dot product of their vectors\"\"\"\n",
    "    similarity = 0\n",
    "    word1=word1.lower()\n",
    "    word2=word2.lower()\n",
    "    if word1 in model and word2 in model:\n",
    "        word1_vec = model[word1]\n",
    "        word2_vec = model[word2]\n",
    "        similarity = np.dot(word1_vec, word2_vec)\n",
    "    return similarity\n",
    "\n",
    "def get_word_list_from_aspect_candidates(seed_word, word_tf_idf, similarity_threshold, score_threshold):\n",
    "    \"\"\"Method 1: directly find the word list from all words whose similarity with the seed_word and tf-idf score are above \n",
    "    certain threshold\"\"\"\n",
    "    word_list = []\n",
    "    for word_data in word_tf_idf:\n",
    "        word = word_data[0]\n",
    "        tf_idf = word_data[1]\n",
    "        if tf_idf > score_threshold:\n",
    "            similarity = get_similarity(seed_word, word)\n",
    "            if similarity > similarity_threshold:\n",
    "                word_list.append([word, similarity, tf_idf])              \n",
    "    word_list_sorted = sorted(word_list, key=lambda tup: tup[1], reverse=True)\n",
    "    return word_list_sorted\n",
    "\n",
    "\n",
    "def get_word_list_by_tf_idf(seed_word_list, sentence_list, num_words_in_list, sim_slope = 0.5, sim_intercept = 0.2):\n",
    "    \"\"\"Method 2: Find the word_list who can distinguish the chosen sentences from other sentences\"\"\"\n",
    "    \n",
    "    # For each seed_word in seed_word_list, get the word_data for all sentences. word_data has 4 fields [num_word_total, num_doc_total, \n",
    "    # num_word_in_topic, num_doc_in_topic, similarity with seed_word], the first two are from all sentences, and the latter two are from the sentences \n",
    "    # that contain the seed_word.   \n",
    "    num_seed_word = len(seed_word_list)\n",
    "    word_statistics_dic_list = [{} for i in range(num_seed_word)]\n",
    "    \n",
    "    num_sentence_topic_list = [0 for k in range(num_seed_word)]\n",
    "    num_sentence_total_list = [0 for k in range(num_seed_word)]\n",
    "    i = 0\n",
    "#     print \"Number of sentences processed:\"\n",
    "    for sentence in sentence_list: \n",
    "        i += 1\n",
    "        if i % 50000 == 0:\n",
    "            print i\n",
    "        tokens = tokenize(sentence, stem = False)\n",
    "        tokens_count = Counter(tokens)\n",
    "        for word in tokens_count:\n",
    "            # check for each seed_word:\n",
    "            for k in range(num_seed_word):\n",
    "                seed_word = seed_word_list[k]\n",
    "                if seed_word in sentence: \n",
    "                    num_sentence_topic_list[k] += 1\n",
    "                    num_sentence_total_list[k] += 1\n",
    "                    if word not in word_statistics_dic_list[k]:\n",
    "                        word_statistics_dic_list[k][word] = [tokens_count[word], 1, tokens_count[word], 1]\n",
    "                    else:\n",
    "                        word_statistics_dic_list[k][word][0] += tokens_count[word]\n",
    "                        word_statistics_dic_list[k][word][1] += 1\n",
    "                        word_statistics_dic_list[k][word][2] += tokens_count[word]\n",
    "                        word_statistics_dic_list[k][word][3] += 1\n",
    "                else:\n",
    "                    num_sentence_total_list[k] += 1\n",
    "                    if word not in word_statistics_dic_list[k]:\n",
    "                        word_statistics_dic_list[k][word] = [tokens_count[word], 1, 0, 0]\n",
    "                    else:\n",
    "                        word_statistics_dic_list[k][word][0] += tokens_count[word]\n",
    "                        word_statistics_dic_list[k][word][1] += 1\n",
    "\n",
    "    # Get the maximum word frequency for each seed_word group:\n",
    "    word_tf_idf_ratio_list = [[] for k in range(num_seed_word)]\n",
    "    max_num_word_total_list =[0 for k in range(num_seed_word)]\n",
    "    max_num_word_topic_list =[0 for k in range(num_seed_word)] \n",
    "    for k in range(num_seed_word):    \n",
    "        for word in word_statistics_dic_list[k]:\n",
    "            word_data = word_statistics_dic_list[k][word]\n",
    "            if word_data[0] > max_num_word_total_list[k]:\n",
    "                max_num_word_total_list[k] = word_data[0]\n",
    "            if word_data[2] > max_num_word_topic_list[k]:\n",
    "                max_num_word_topic_list[k] = word_data[2]\n",
    "    \n",
    "    # Get tf_idf adjusted ratio for each word, to measure how this word can distinguish the topic sentences:\n",
    "    for k in range(num_seed_word):        \n",
    "        for word in word_statistics_dic_list[k]:\n",
    "            word_data = word_statistics_dic_list[k][word]\n",
    "            num_word_total = word_data[0]\n",
    "            num_word_topic = word_data[2]\n",
    "            num_doc_total = word_data[1]   \n",
    "            num_doc_topic = word_data[3]\n",
    "        \n",
    "            if num_doc_topic == 0 or num_doc_total == 0:\n",
    "                word_tf_idf_ratio_list[k].append([word, 0, 0, 0])\n",
    "                continue\n",
    "\n",
    "            tf_topic = float(num_word_topic) / max_num_word_topic_list[k]\n",
    "            tf_total = float(num_word_total) / max_num_word_total_list[k]\n",
    "            tf_ratio = (tf_topic/num_word_topic) / (tf_total/num_doc_total)\n",
    "\n",
    "            idf_topic = math.log(float(num_sentence_topic_list[k]) / num_doc_topic)\n",
    "            idf_total = math.log(float(num_sentence_total_list[k]) / num_doc_total) \n",
    "\n",
    "            word_tf_idf_ratio_list[k].append([word, 0, 0, tf_topic * math.log(tf_ratio) * idf_total ** 2, tf_topic, tf_total, tf_ratio, idf_topic, idf_total])\n",
    "\n",
    "        word_tf_idf_ratio_list[k].sort(key=lambda tup: tup[3], reverse=True)\n",
    " \n",
    "    for k in range(num_seed_word): \n",
    "        for j in range(100):\n",
    "            word_data = word_tf_idf_ratio_list[k][j]\n",
    "            word = word_data[0]\n",
    "            similarity = get_similarity(word, seed_word_list[k])\n",
    "            sim_amplify = sim_intercept + similarity * sim_slope\n",
    "            word_tf_idf_ratio_list[k][j][2] = sim_amplify\n",
    "            argument = 1 + word_tf_idf_ratio_list[k][j][3] * sim_amplify\n",
    "            if argument > 0:\n",
    "                word_tf_idf_ratio_list[k][j][1] = math.log(argument) \n",
    "            else:\n",
    "                word_tf_idf_ratio_list[k][j][1] = -1\n",
    "        word_tf_idf_ratio_list[k].sort(key=lambda tup: tup[1], reverse=True)\n",
    "\n",
    "    word_tf_idf_ratio_list = [item[:num_words_in_list] for item in word_tf_idf_ratio_list]\n",
    "    word_list = {}\n",
    "    for k in range(num_seed_word):\n",
    "        word_list[seed_word_list[k]] = [[word_data[0],word_data[1]] for word_data in word_tf_idf_ratio_list[k][:num_words_in_list]]\n",
    "    return word_list, word_tf_idf_ratio_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "100000\n",
      "150000\n",
      "200000\n",
      "\"service\": \n",
      "   \"service\", 4.37;  \"customer\", 2.67;  \"services\", 2.01;  \"phone\", 1.90;  \"minutes\", 1.60;  \"mobile\", 1.52;  \"month\", 1.31;  \"net\", 1.28;  \"days\", 1.27;  \"year\", 1.20; \n",
      "\"battery\": \n",
      "   \"battery\", 4.35;  \"charge\", 1.83;  \"phone\", 1.83;  \"life\", 1.63;  \"hours\", 1.31;  \"drain\", 1.30;  \"use\", 1.29;  \"remove\", 1.26;  \"screen\", 1.23;  \"fast\", 1.17; \n",
      "\"text\": \n",
      "   \"text\", 4.75;  \"texts\", 3.57;  \"messages\", 2.75;  \"message\", 2.68;  \"texting\", 2.57;  \"phone\", 2.46;  \"data\", 2.33;  \"keyboard\", 2.28;  \"calls\", 2.02;  \"web\", 2.00; \n",
      "\"screen\": \n",
      "   \"screen\", 4.30;  \"touch\", 2.76;  \"touchscreen\", 2.05;  \"phone\", 1.96;  \"screens\", 1.94;  \"keyboard\", 1.90;  \"camera\", 1.55;  \"button\", 1.51;  \"buttons\", 1.33;  \"size\", 1.29; \n",
      "\"apps\": \n",
      "   \"apps\", 4.64;  \"download\", 2.29;  \"phone\", 2.15;  \"memory\", 2.13;  \"app\", 2.01;  \"sd\", 2.00;  \"google\", 1.99;  \"card\", 1.83;  \"install\", 1.80;  \"storage\", 1.64; \n",
      "\"camera\": \n",
      "   \"camera\", 4.77;  \"video\", 2.57;  \"flash\", 2.49;  \"phone\", 2.17;  \"cameras\", 2.14;  \"front\", 2.11;  \"mp\", 2.09;  \"pictures\", 2.09;  \"screen\", 2.06;  \"quality\", 1.85; \n",
      "\"call\": \n",
      "   \"call\", 4.18;  \"calls\", 3.71;  \"calling\", 2.77;  \"called\", 2.67;  \"phone\", 2.63;  \"make\", 2.49;  \"get\", 2.06;  \"automatically\", 1.90;  \"use\", 1.82;  \"hear\", 1.79; \n",
      "\"plan\": \n",
      "   \"plan\", 4.94;  \"plans\", 3.59;  \"data\", 2.70;  \"month\", 2.29;  \"contract\", 2.12;  \"pay\", 2.06;  \"unlimited\", 2.02;  \"phone\", 2.00;  \"service\", 1.90;  \"monthly\", 1.87; \n",
      "\"keyboard\": \n",
      "   \"keyboard\", 5.00;  \"qwerty\", 3.32;  \"slide\", 2.73;  \"screen\", 2.51;  \"phone\", 2.31;  \"keys\", 2.26;  \"keyboards\", 2.26;  \"typing\", 1.98;  \"use\", 1.91;  \"touchscreen\", 1.89; \n",
      "\"data\": \n",
      "   \"data\", 5.03;  \"plan\", 2.70;  \"unlimited\", 2.58;  \"phone\", 2.35;  \"wifi\", 2.27;  \"text\", 2.24;  \"mb\", 1.97;  \"minutes\", 1.95;  \"use\", 1.90;  \"month\", 1.85; \n",
      "\"price\": \n",
      "   \"price\", 4.67;  \"prices\", 2.33;  \"good\", 2.08;  \"phone\", 2.04;  \"priced\", 1.93;  \"low\", 1.67;  \"worth\", 1.55;  \"better\", 1.52;  \"great\", 1.48;  \"paid\", 1.43; \n",
      "\"card\": \n",
      "   \"card\", 4.62;  \"sd\", 2.86;  \"cards\", 2.85;  \"sim\", 2.81;  \"gb\", 2.49;  \"memory\", 2.40;  \"phone\", 2.39;  \"micro\", 2.09;  \"slot\", 1.91;  \"minutes\", 1.90; \n"
     ]
    }
   ],
   "source": [
    "seed_word_list = [\"battery\",\"pictures\",\"price\",\"zoom\",\"ease of use\",\"detection\",\"design\",\"video\",\"quality\",\"screen\",\"size\"] # Camera\n",
    "seed_word_list = ['screen', \"battery\", \"price\", \"keyboard\", \"wifi\", \"games\", \"touch\", \"quality\",\"camera\",\"video\"] # Tablets\n",
    "seed_word_list = [\"service\", \"battery\", \"screen\", \"text\", \"apps\", \"card\", \"call\", \"plan\", \"price\", \"keyboard\",\"data\", \"camera\"] # no contract phones\n",
    "sim_slope = 1\n",
    "sim_intercept = 0.2\n",
    "wordlist_dict, _ = get_word_list_by_tf_idf(seed_word_list, sentence_list, 10, sim_slope, sim_intercept)\n",
    "num_seed_word = len(word_list)\n",
    "for aspect in word_list:\n",
    "    print '\"{0}\": '.format(aspect)\n",
    "    print '  ',\n",
    "    for word_data in word_list[aspect]:\n",
    "        print '\"%s\", %0.2f; '%(word_data[0], word_data[1]),\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def writeWordlistDictToDB(category, wordlist_dict):\n",
    "    client, db = connect_to_db()\n",
    "    query = {\"category\": list(category)}\n",
    "    update_field = {\"wordlist_dict\": wordlist_dict}\n",
    "    db.category_collection.update_one(query, {\"$set\": update_field}, True)\n",
    "    client.close()\n",
    "\n",
    "def getWordlistDictFromDB(category):\n",
    "    client, db = connect_to_db()\n",
    "    category_collection = db.category_collection\n",
    "    query_res = list(category_collection.find({\"category\": category}))\n",
    "    disconnect_db(client)\n",
    "\n",
    "    if len(query_res) < 1:\n",
    "        raise Exception('Category: {0} not found in database'.format(category))\n",
    "    elif len(query_res) > 1:\n",
    "        raise Exception('Category: {0} found multiple occurances in database'.format(category))\n",
    "\n",
    "    result = query_res[0]\n",
    "    wordlistDictWithWeights = result['wordlist_dict']\n",
    "    wordlistDict = {}\n",
    "    for aspect in wordlistDictWithWeights:\n",
    "        wordlistDict[aspect] = [sublist[0] for sublist in wordlistDictWithWeights[aspect]]\n",
    "\n",
    "    return wordlistDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "category = (u'Cell Phones & Accessories', u'Cell Phones', u'No-Contract Cell Phones')\n",
    "writeWordlistDictToDB(category, wordlist_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
